{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQ1c1cZoUpDbc4RwJmRr+p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nniikkoollaass/data-science-modul-13-HW/blob/main/DS_HW_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Частина 1\n",
        "\n",
        "​\n",
        "\n",
        "В якості домашнього завдання вам пропонується створити нейронну мережу за допомогою механізмів Keras, яка буде класифікувати товари із датасету fasion_mnist.\n",
        "\n",
        "\n",
        "\n",
        "На відміну від попереднього завдання вам пропонується створити згорткову нейромережу. Підберіть архітектуру мережі та навчіть її на даних із датасету fasion_mnist. Спробуйте досягти максимально можливої точності класифікації за рахунок маніпуляції параметрами мережі. Порівняйте точність отриманої згорткової мережі з точністю багатошарової мережі з попереднього завдання. Зробіть висновки."
      ],
      "metadata": {
        "id": "vTx6HlYyMZZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Завантаження даних\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Зміна форми даних\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# Нормалізація даних\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Перетворення міток у категоріальний формат\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Створення моделі\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компіляція моделі\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Навчання моделі\n",
        "history = model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Оцінка моделі\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_bsxFSxMdWp",
        "outputId": "f961345f-c53a-436c-d5e9-4f790ed14a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "750/750 [==============================] - 56s 71ms/step - loss: 0.6538 - accuracy: 0.7643 - val_loss: 0.3891 - val_accuracy: 0.8578\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 49s 66ms/step - loss: 0.4027 - accuracy: 0.8572 - val_loss: 0.3270 - val_accuracy: 0.8813\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 48s 65ms/step - loss: 0.3397 - accuracy: 0.8791 - val_loss: 0.3155 - val_accuracy: 0.8817\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 49s 65ms/step - loss: 0.3079 - accuracy: 0.8894 - val_loss: 0.2968 - val_accuracy: 0.8856\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.2841 - accuracy: 0.8989 - val_loss: 0.2801 - val_accuracy: 0.8958\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.2581 - accuracy: 0.9075 - val_loss: 0.2644 - val_accuracy: 0.9022\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.2396 - accuracy: 0.9135 - val_loss: 0.2594 - val_accuracy: 0.9052\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 50s 66ms/step - loss: 0.2277 - accuracy: 0.9167 - val_loss: 0.2486 - val_accuracy: 0.9101\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 51s 69ms/step - loss: 0.2085 - accuracy: 0.9243 - val_loss: 0.2435 - val_accuracy: 0.9136\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 50s 66ms/step - loss: 0.1968 - accuracy: 0.9286 - val_loss: 0.2545 - val_accuracy: 0.9092\n",
            "313/313 [==============================] - 3s 11ms/step - loss: 0.2647 - accuracy: 0.9063\n",
            "Test accuracy: 0.9063000082969666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Порівняння результатів багатошарової нейронної мережі (MLP) та згорткової нейронної мережі (CNN)\n",
        "\n",
        "\n",
        "\n",
        "Результати багатошарової нейронної мережі (MLP)\n",
        "\n",
        "Точність на валідаційному наборі даних (validation accuracy):\n",
        "Початкова точність після першої епохи: 84.48%\n",
        "Максимальна точність після навчання: 89.00%\n",
        "\n",
        "Втрата на валідаційному наборі даних (validation loss):\n",
        "Початкова втрата після першої епохи: 0.4337\n",
        "Найменша втрата після навчання: 0.3041\n",
        "\n",
        "Точність на тестовому наборі даних (test accuracy): 88.65%\n",
        "\n",
        "\n",
        "Результати згорткової нейронної мережі (CNN)\n",
        "\n",
        "Точність на валідаційному наборі даних (validation accuracy):\n",
        "Початкова точність після першої епохи: 85.78%\n",
        "Максимальна точність після навчання: 91.36%\n",
        "\n",
        "Втрата на валідаційному наборі даних (validation loss):\n",
        "Початкова втрата після першої епохи: 0.3891\n",
        "Найменша втрата після навчання: 0.2435\n",
        "\n",
        "Точність на тестовому наборі даних (test accuracy): 90.63%\n",
        "\n",
        "\n",
        "Висновки\n",
        "\n",
        "Точність моделі:\n",
        "\n",
        " Згорткова нейронна мережа (CNN) показала вищу точність на тестових даних (90.63%) у порівнянні з багатошаровою нейронною мережею (MLP) (88.65%). Це підтверджує, що CNN краще справляється з класифікацією зображень, ніж MLP, завдяки здатності виявляти просторові характеристики зображень.\n",
        "\n",
        "Втрата:\n",
        "\n",
        "CNN також показала меншу втрату на валідаційному наборі даних (0.2435) у порівнянні з MLP (0.3041). Це означає, що модель краще навчалася на тренувальних даних і має кращу здатність до узагальнення.\n",
        "\n",
        "Переваги CNN:\n",
        "\n",
        "Використання згорткових шарів у CNN дозволяє ефективніше витягувати ознаки з зображень, що робить цю архітектуру більш придатною для задач, пов'язаних з обробкою зображень.\n",
        "\n",
        "\n",
        "Загальний висновок\n",
        "\n",
        "Згорткова нейронна мережа (CNN) виявилася більш ефективною для задачі класифікації зображень з датасету Fashion MNIST, досягнувши вищої точності і меншої втрати в порівнянні з багатошаровою нейронною мережею (MLP). Це демонструє перевагу використання CNN для подібних задач і підтверджує її здатність краще витягувати і класифікувати просторові ознаки зображень."
      ],
      "metadata": {
        "id": "qRtaN0GXP1dO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Частина 2\n",
        "\n",
        "​\n",
        "\n",
        "В цій частині ми знову будемо працювати з датасетом fasion_mnist.\n",
        "\n",
        "\n",
        "\n",
        "На відміну від попереднього завдання вам пропонується створити згорткову нейромережу, що використовує VGG16 в якості згорткової основи.\n",
        "\n",
        "\n",
        "\n",
        "Навчіть отриману мережу на даних із датасету fasion_mnist. Спробуйте досягти максимально можливої точності класифікації за рахунок маніпуляції параметрами мережі. Під час навчання використовуйте прийоми донавчання та виділення ознак.\n",
        "\n",
        "\n",
        "\n",
        "Порівняйте точність отриманої згорткової мережі з точністю багатошарової мережі з попереднього завдання. Зробіть висновки."
      ],
      "metadata": {
        "id": "YC-Pz9i7Qowx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "# Завантаження датасету\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Змінення розмірів зображень до формату, необхідного для MobileNetV2\n",
        "x_train = np.repeat(x_train[..., np.newaxis], 3, -1)  # Перетворення на RGB\n",
        "x_test = np.repeat(x_test[..., np.newaxis], 3, -1)    # Перетворення на RGB\n",
        "\n",
        "# Зміна розмірів зображень до 64x64, щоб ще більше зменшити використання пам'яті\n",
        "x_train = tf.image.resize(x_train, (64, 64))\n",
        "x_test = tf.image.resize(x_test, (64, 64))\n",
        "\n",
        "# Нормалізація зображень\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Кодування міток\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Завантаження попередньо натренованої моделі MobileNetV2 без верхніх шарів\n",
        "mobilenet_v2_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "\n",
        "# Замороження шарів базової моделі\n",
        "for layer in mobilenet_v2_base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Додавання нових шарів до базової моделі\n",
        "x = GlobalAveragePooling2D()(mobilenet_v2_base.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Створення нової моделі\n",
        "model = Model(inputs=mobilenet_v2_base.input, outputs=output)\n",
        "\n",
        "# Компіляція моделі\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Навчання моделі з ще меншим batch size\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=16, validation_split=0.2)\n",
        "\n",
        "# Оцінка моделі на тестовому наборі даних\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_accuracy}')\n"
      ],
      "metadata": {
        "id": "LYkZtBjMQsyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6b7f5d-fa49-40e3-c2c8-4cd58960d30e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "3000/3000 [==============================] - 198s 65ms/step - loss: 0.6159 - accuracy: 0.7869 - val_loss: 0.4253 - val_accuracy: 0.8461\n",
            "Epoch 2/10\n",
            "3000/3000 [==============================] - 186s 62ms/step - loss: 0.4687 - accuracy: 0.8315 - val_loss: 0.4111 - val_accuracy: 0.8472\n",
            "Epoch 3/10\n",
            "3000/3000 [==============================] - 200s 67ms/step - loss: 0.4327 - accuracy: 0.8441 - val_loss: 0.3967 - val_accuracy: 0.8562\n",
            "Epoch 4/10\n",
            "3000/3000 [==============================] - 194s 65ms/step - loss: 0.4092 - accuracy: 0.8507 - val_loss: 0.3916 - val_accuracy: 0.8602\n",
            "Epoch 5/10\n",
            "3000/3000 [==============================] - 194s 65ms/step - loss: 0.3849 - accuracy: 0.8591 - val_loss: 0.3854 - val_accuracy: 0.8648\n",
            "Epoch 6/10\n",
            "3000/3000 [==============================] - 192s 64ms/step - loss: 0.3681 - accuracy: 0.8646 - val_loss: 0.3941 - val_accuracy: 0.8582\n",
            "Epoch 7/10\n",
            "3000/3000 [==============================] - 194s 65ms/step - loss: 0.3570 - accuracy: 0.8671 - val_loss: 0.4126 - val_accuracy: 0.8568\n",
            "Epoch 8/10\n",
            "3000/3000 [==============================] - 194s 65ms/step - loss: 0.3379 - accuracy: 0.8739 - val_loss: 0.4088 - val_accuracy: 0.8622\n",
            "Epoch 9/10\n",
            "3000/3000 [==============================] - 194s 65ms/step - loss: 0.3330 - accuracy: 0.8773 - val_loss: 0.4039 - val_accuracy: 0.8618\n",
            "Epoch 10/10\n",
            "3000/3000 [==============================] - 196s 65ms/step - loss: 0.3185 - accuracy: 0.8812 - val_loss: 0.4206 - val_accuracy: 0.8624\n",
            "313/313 [==============================] - 29s 88ms/step - loss: 0.4162 - accuracy: 0.8629\n",
            "Test accuracy: 0.8629000186920166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновки\n",
        "\n",
        "Точність:\n",
        "Тестова точність багатошарової нейронної мережі становить 88.65%, тоді як тестова точність мережі на основі MobileNetV2 становить 86.29%. Багатошарова нейронна мережа показала кращу точність на тестовому наборі даних.\n",
        "\n",
        "Швидкість навчання:\n",
        "MobileNetV2 навчалася протягом 10 епох з кожною епохою, що займає приблизно 194-200 секунд.\n",
        "Багатошарова нейронна мережа навчалася протягом 24 епох з кожною епохою, що займає приблизно 2-5 секунд.\n",
        "MobileNetV2 потребує більше часу на навчання за епоху, але завершила навчання всього за 10 епох.\n",
        "\n",
        "Використання пам'яті:\n",
        "MobileNetV2 зменшила використання пам'яті завдяки зменшенню розміру зображень і менш складній моделі. Однак вона все одно споживає більше пам'яті, ніж багатошарова нейронна мережа, через свою складнішу архітектуру.\n",
        "\n",
        "Втрати:\n",
        "Багатошарова нейронна мережа показує стабільніше зниження втрат (loss) протягом епох порівняно з MobileNetV2, де втрати залишаються на вищому рівні, особливо під час валідації.\n",
        "\n",
        "Узагальнення:\n",
        "Якщо основний пріоритет — точність, багатошарова нейронна мережа є кращим варіантом для цього завдання.\n",
        "Якщо необхідно зменшити використання пам'яті і прийнятна менша точність, MobileNetV2 може бути підходящим вибором."
      ],
      "metadata": {
        "id": "o4N-00k-b81W"
      }
    }
  ]
}